{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from mediapipe_model_maker import object_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-06 17:31:55--  https://storage.googleapis.com/mediapipe-tasks/object_detector/android_figurine.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.214.27, 142.250.179.219, 142.251.36.27, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.214.27|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28607322 (27M) [application/zip]\n",
      "Saving to: ‘android_figurine.zip’\n",
      "\n",
      "android_figurine.zi 100%[===================>]  27,28M  5,26MB/s    in 6,8s    \n",
      "\n",
      "2024-09-06 17:32:03 (4,03 MB/s) - ‘android_figurine.zip’ saved [28607322/28607322]\n",
      "\n",
      "Archive:  android_figurine.zip\n",
      "   creating: android_figurine/\n",
      "   creating: android_figurine/validation/\n",
      "  inflating: android_figurine/validation/labels.json  \n",
      "   creating: android_figurine/validation/images/\n",
      "  inflating: android_figurine/validation/images/IMG_0502.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0497.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0501.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0496.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0493.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0494.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0500.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0499.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0495.jpg  \n",
      "  inflating: android_figurine/validation/images/IMG_0498.jpg  \n",
      "   creating: android_figurine/android_figurine/\n",
      "   creating: android_figurine/android_figurine/validation/\n",
      "  inflating: android_figurine/android_figurine/validation/labels.json  \n",
      "   creating: android_figurine/android_figurine/validation/images/\n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0502.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0497.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0501.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0496.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0493.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0494.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0500.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0499.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0495.jpg  \n",
      "  inflating: android_figurine/android_figurine/validation/images/IMG_0498.jpg  \n",
      "   creating: android_figurine/android_figurine/train/\n",
      "  inflating: android_figurine/android_figurine/train/labels.json  \n",
      "   creating: android_figurine/android_figurine/train/images/\n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0530.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0521.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0517.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0562.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0516.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0525.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0542.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0556.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0536.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0533.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0515.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0510.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0531.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0555.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0558.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0541.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0543.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0547.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0529.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0514.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0523.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0545.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0568.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0522.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0534.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0567.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0557.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0565.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0571.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0548.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0569.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0559.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0546.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0552.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0561.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0511.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0551.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0566.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0544.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0518.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0554.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0509.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0549.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0538.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0537.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0539.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0550.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0519.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0560.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0553.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0540.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0524.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0520.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0527.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0532.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0513.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0564.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0526.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0528.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0535.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0563.jpg  \n",
      "  inflating: android_figurine/android_figurine/train/images/IMG_0512.jpg  \n",
      "   creating: android_figurine/train/\n",
      "  inflating: android_figurine/train/labels.json  \n",
      "   creating: android_figurine/train/images/\n",
      "  inflating: android_figurine/train/images/IMG_0530.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0521.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0517.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0562.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0516.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0525.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0542.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0556.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0536.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0533.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0515.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0510.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0531.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0555.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0558.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0541.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0543.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0547.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0529.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0514.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0523.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0545.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0568.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0522.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0534.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0567.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0557.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0565.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0571.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0548.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0569.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0559.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0546.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0552.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0561.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0511.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0551.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0566.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0544.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0518.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0554.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0509.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0549.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0538.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0537.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0539.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0550.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0519.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0560.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0553.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0540.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0524.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0520.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0527.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0532.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0513.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0564.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0526.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0528.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0535.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0563.jpg  \n",
      "  inflating: android_figurine/train/images/IMG_0512.jpg  \n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/mediapipe-tasks/object_detector/android_figurine.zip\n",
    "!unzip android_figurine.zip\n",
    "train_dataset_path = \"android_figurine/train\"\n",
    "validation_dataset_path = \"android_figurine/validation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: background\n",
      "1: android\n",
      "2: pig_android\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(train_dataset_path, \"labels.json\"), \"r\") as f:\n",
    "  labels_json = json.load(f)\n",
    "for category_item in labels_json[\"categories\"]:\n",
    "  print(f\"{category_item['id']}: {category_item['name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:On image 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:46:20.708195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 17:46:20.996679: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:On image 0\n",
      "train_data size:  62\n",
      "validation_data size:  10\n"
     ]
    }
   ],
   "source": [
    "train_data = object_detector.Dataset.from_coco_folder(train_dataset_path, cache_dir=\"/tmp/od_data/train\")\n",
    "validation_data = object_detector.Dataset.from_coco_folder(validation_dataset_path, cache_dir=\"/tmp/od_data/validation\")\n",
    "print(\"train_data size: \", train_data.size)\n",
    "print(\"validation_data size: \", validation_data.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = object_detector.SupportedModels.MOBILENET_MULTI_AVG\n",
    "hparams = object_detector.HParams(export_dir='exported_model')\n",
    "options = object_detector.ObjectDetectorOptions(\n",
    "    supported_model=spec,\n",
    "    hparams=hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/.local/lib/python3.8/site-packages/keras/src/engine/functional.py:639: UserWarning: Input dict contained keys ['6'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/tf_model_garden/vision/qat/mobilenetv3.5_ssd_coco/mobilenetv3.5_ssd_i256_ckpt.tar.gz to /tmp/model_maker/object_detector/mobilenetmultiavg\n",
      "Model: \"retina_net_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobile_net (MobileNet)      {'2': (None, 64, 64, 32   3704416   \n",
      "                             ),                                  \n",
      "                              '3': (None, 32, 32, 64             \n",
      "                             ),                                  \n",
      "                              '4': (None, 16, 16, 16             \n",
      "                             0),                                 \n",
      "                              '5': (None, 8, 8, 192)             \n",
      "                             , '6': (None, 1, 1, 128             \n",
      "                             0)}                                 \n",
      "                                                                 \n",
      " fpn (FPN)                   {'5': (None, 8, 8, 128)   144928    \n",
      "                             , '4': (None, 16, 16, 1             \n",
      "                             28),                                \n",
      "                              '3': (None, 32, 32, 12             \n",
      "                             8),                                 \n",
      "                              '6': (None, 4, 4, 128)             \n",
      "                             , '7': (None, 2, 2, 128             \n",
      "                             )}                                  \n",
      "                                                                 \n",
      " multilevel_detection_gener  multiple                  0 (unused)\n",
      " ator (MultilevelDetectionG                                      \n",
      " enerator)                                                       \n",
      "                                                                 \n",
      " retina_net_head (RetinaNet  ({'3': (None, 32, 32, 2   172223    \n",
      " Head)                       7),                                 \n",
      "                              '4': (None, 16, 16, 27             \n",
      "                             ),                                  \n",
      "                              '5': (None, 8, 8, 27),             \n",
      "                              '6': (None, 4, 4, 27),             \n",
      "                              '7': (None, 2, 2, 27)}             \n",
      "                             , {'3': (None, 32, 32,              \n",
      "                             36),                                \n",
      "                              '4': (None, 16, 16, 36             \n",
      "                             ),                                  \n",
      "                              '5': (None, 8, 8, 36),             \n",
      "                              '6': (None, 4, 4, 36),             \n",
      "                              '7': (None, 2, 2, 36)}             \n",
      "                             , {})                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4021567 (15.34 MB)\n",
      "Trainable params: 3973503 (15.16 MB)\n",
      "Non-trainable params: 48064 (187.75 KB)\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Training the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Training the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jesse/.local/lib/python3.8/site-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0', 'conv2dbn_block_2/batch_normalization/gamma:0', 'conv2dbn_block_2/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0', 'conv2dbn_block_2/batch_normalization/gamma:0', 'conv2dbn_block_2/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0', 'conv2dbn_block_2/batch_normalization/gamma:0', 'conv2dbn_block_2/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0', 'conv2dbn_block_2/batch_normalization/gamma:0', 'conv2dbn_block_2/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0', 'conv2dbn_block_2/batch_normalization/gamma:0', 'conv2dbn_block_2/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0', 'conv2dbn_block_2/batch_normalization/gamma:0', 'conv2dbn_block_2/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0', 'conv2dbn_block_2/batch_normalization/gamma:0', 'conv2dbn_block_2/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2dbn_block_1/batch_normalization/gamma:0', 'conv2dbn_block_1/batch_normalization/beta:0', 'conv2dbn_block_2/batch_normalization/gamma:0', 'conv2dbn_block_2/batch_normalization/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 42s 2s/step - total_loss: 5.9634 - cls_loss: 5.7791 - box_loss: 0.0024 - model_loss: 5.9005 - val_total_loss: 1.3662 - val_cls_loss: 1.2293 - val_box_loss: 0.0015 - val_model_loss: 1.3034\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 9s 1s/step - total_loss: 1.3948 - cls_loss: 1.2035 - box_loss: 0.0026 - model_loss: 1.3320 - val_total_loss: 1.2406 - val_cls_loss: 1.1423 - val_box_loss: 7.0817e-04 - val_model_loss: 1.1777\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 9s 1s/step - total_loss: 1.2366 - cls_loss: 1.0967 - box_loss: 0.0015 - model_loss: 1.1737 - val_total_loss: 1.1167 - val_cls_loss: 1.0246 - val_box_loss: 5.8479e-04 - val_model_loss: 1.0538\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.9968 - cls_loss: 0.8808 - box_loss: 0.0011 - model_loss: 0.9339 - val_total_loss: 0.9243 - val_cls_loss: 0.8260 - val_box_loss: 7.0774e-04 - val_model_loss: 0.8614\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.7339 - cls_loss: 0.6336 - box_loss: 7.4884e-04 - model_loss: 0.6710 - val_total_loss: 0.7579 - val_cls_loss: 0.6723 - val_box_loss: 4.5436e-04 - val_model_loss: 0.6950\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.6104 - cls_loss: 0.5102 - box_loss: 7.4589e-04 - model_loss: 0.5475 - val_total_loss: 0.6602 - val_cls_loss: 0.5794 - val_box_loss: 3.5816e-04 - val_model_loss: 0.5973\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.5225 - cls_loss: 0.4256 - box_loss: 6.8121e-04 - model_loss: 0.4596 - val_total_loss: 0.5531 - val_cls_loss: 0.4738 - val_box_loss: 3.2845e-04 - val_model_loss: 0.4902\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.4390 - cls_loss: 0.3542 - box_loss: 4.3678e-04 - model_loss: 0.3761 - val_total_loss: 0.4806 - val_cls_loss: 0.3993 - val_box_loss: 3.6860e-04 - val_model_loss: 0.4177\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.4010 - cls_loss: 0.3097 - box_loss: 5.6785e-04 - model_loss: 0.3381 - val_total_loss: 0.4399 - val_cls_loss: 0.3612 - val_box_loss: 3.1576e-04 - val_model_loss: 0.3770\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 10s 2s/step - total_loss: 0.3538 - cls_loss: 0.2639 - box_loss: 5.4082e-04 - model_loss: 0.2909 - val_total_loss: 0.4163 - val_cls_loss: 0.3390 - val_box_loss: 2.8860e-04 - val_model_loss: 0.3534\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 11s 2s/step - total_loss: 0.3215 - cls_loss: 0.2403 - box_loss: 3.6521e-04 - model_loss: 0.2586 - val_total_loss: 0.3835 - val_cls_loss: 0.3053 - val_box_loss: 3.0697e-04 - val_model_loss: 0.3207\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.2992 - cls_loss: 0.2192 - box_loss: 3.4053e-04 - model_loss: 0.2363 - val_total_loss: 0.3587 - val_cls_loss: 0.2777 - val_box_loss: 3.6197e-04 - val_model_loss: 0.2958\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.2914 - cls_loss: 0.2121 - box_loss: 3.2783e-04 - model_loss: 0.2285 - val_total_loss: 0.3436 - val_cls_loss: 0.2633 - val_box_loss: 3.4758e-04 - val_model_loss: 0.2807\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 9s 1s/step - total_loss: 0.2758 - cls_loss: 0.1949 - box_loss: 3.6028e-04 - model_loss: 0.2129 - val_total_loss: 0.3272 - val_cls_loss: 0.2484 - val_box_loss: 3.1893e-04 - val_model_loss: 0.2644\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.2641 - cls_loss: 0.1866 - box_loss: 2.9136e-04 - model_loss: 0.2012 - val_total_loss: 0.3183 - val_cls_loss: 0.2395 - val_box_loss: 3.1842e-04 - val_model_loss: 0.2554\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.2497 - cls_loss: 0.1703 - box_loss: 3.3090e-04 - model_loss: 0.1869 - val_total_loss: 0.3120 - val_cls_loss: 0.2326 - val_box_loss: 3.3009e-04 - val_model_loss: 0.2491\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 9s 1s/step - total_loss: 0.2524 - cls_loss: 0.1760 - box_loss: 2.7078e-04 - model_loss: 0.1895 - val_total_loss: 0.3040 - val_cls_loss: 0.2265 - val_box_loss: 2.9357e-04 - val_model_loss: 0.2411\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.2330 - cls_loss: 0.1584 - box_loss: 2.3318e-04 - model_loss: 0.1701 - val_total_loss: 0.2953 - val_cls_loss: 0.2176 - val_box_loss: 2.9589e-04 - val_model_loss: 0.2324\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 10s 1s/step - total_loss: 0.2306 - cls_loss: 0.1539 - box_loss: 2.7770e-04 - model_loss: 0.1678 - val_total_loss: 0.2942 - val_cls_loss: 0.2162 - val_box_loss: 3.0285e-04 - val_model_loss: 0.2313\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 9s 1s/step - total_loss: 0.2492 - cls_loss: 0.1668 - box_loss: 3.9072e-04 - model_loss: 0.1864 - val_total_loss: 0.2834 - val_cls_loss: 0.2034 - val_box_loss: 3.4106e-04 - val_model_loss: 0.2205\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 9s 1s/step - total_loss: 0.2122 - cls_loss: 0.1355 - box_loss: 2.7784e-04 - model_loss: 0.1494 - val_total_loss: 0.2763 - val_cls_loss: 0.1975 - val_box_loss: 3.1825e-04 - val_model_loss: 0.2134\n",
      "Epoch 22/30\n"
     ]
    }
   ],
   "source": [
    "model = object_detector.ObjectDetector.create(\n",
    "    train_data=train_data,\n",
    "    validation_data=validation_data,\n",
    "    options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, coco_metrics = model.evaluate(validation_data, batch_size=4)\n",
    "print(f\"Validation loss: {loss}\")\n",
    "print(f\"Validation coco metrics: {coco_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_hparams = object_detector.QATHParams(learning_rate=0.3, batch_size=4, epochs=10, decay_steps=6, decay_rate=0.96)\n",
    "model.quantization_aware_training(train_data, validation_data, qat_hparams=qat_hparams)\n",
    "qat_loss, qat_coco_metrics = model.evaluate(validation_data)\n",
    "print(f\"QAT validation loss: {qat_loss}\")\n",
    "print(f\"QAT validation coco metrics: {qat_coco_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qat_hparams = object_detector.QATHParams(learning_rate=0.9, batch_size=4, epochs=15, decay_steps=5, decay_rate=0.96)\n",
    "model.restore_float_ckpt()\n",
    "model.quantization_aware_training(train_data, validation_data, qat_hparams=new_qat_hparams)\n",
    "qat_loss, qat_coco_metrics = model.evaluate(validation_data)\n",
    "print(f\"QAT validation loss: {qat_loss}\")\n",
    "print(f\"QAT validation coco metrics: {qat_coco_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_model('model_int8_qat.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe_model_maker import quantization\n",
    "quantization_config = quantization.QuantizationConfig.for_float16()\n",
    "model.restore_float_ckpt()\n",
    "model.export_model(model_name=\"model_fp16.tflite\", quantization_config=quantization_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
